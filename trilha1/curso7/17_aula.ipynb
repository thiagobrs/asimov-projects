{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b314687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0debae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "# Ensure the OPENAI_API_KEY is set\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if openai.api_key is None:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable not set\")\n",
    "\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38a5d16",
   "metadata": {},
   "source": [
    "# Analyze images\n",
    "Vision is the ability for a model to \"see\" and understand images. If there is text in an image, the model can also understand the text. It can understand most visual elements, including objects, shapes, colors, and textures, even if there are some limitations.\n",
    "\n",
    "We can provide images as input to generation requests in multiple ways:\n",
    "- By providing a fully qualified URL to an image file\n",
    "- By providing an image as a Base64-encoded data URL\n",
    "- By providing a file ID (created with the Files API)\n",
    "\n",
    "We can provide multiple images as input in a single request by including multiple images in the content array, but keep in mind that images count as tokens and **will be billed accordingly**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc479618",
   "metadata": {},
   "source": [
    "## Image as URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8680659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows a scenic landscape with a wooden boardwalk path running through a lush green field. The field is filled with tall grass and some scattered bushes. In the distance, there are more trees and shrubs. The sky above is wide and blue, with wispy clouds spread across it, suggesting a calm and pleasant day. The overall scene is bright, vibrant, and tranquil.\n"
     ]
    }
   ],
   "source": [
    "client = openai.OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"input_text\", \"text\": \"what's in this image?\"},\n",
    "            {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "            },\n",
    "        ],\n",
    "    }],\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983b5159",
   "metadata": {},
   "source": [
    "## Image as Base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056b42d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image is an illustration depicting a veterinarian and a young boy using stethoscopes to check the health of a small otter. The veterinarian is wearing a white coat, and both he and the boy have friendly expressions as they care for the animal. The scene takes place indoors, with a plant visible in the background.\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"arquivos/otter.png\"\n",
    "\n",
    "# Getting the Base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                { \"type\": \"input_text\", \"text\": \"what's in this image?\" },\n",
    "                {\n",
    "                    \"type\": \"input_image\",\n",
    "                    \"image_url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b971824",
   "metadata": {},
   "source": [
    "## Image as File ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb922821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image depicts a veterinarian examining a small animal, which appears to be a ferret. The veterinarian is using a stethoscope to listen to the animal's heart, and a young boy is holding the ferret. The setting looks like a veterinary clinic or an examination room.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "# Function to create a file with the Files API\n",
    "def create_file(file_path):\n",
    "  with open(file_path, \"rb\") as file_content:\n",
    "    result = client.files.create(\n",
    "        file=file_content,\n",
    "        purpose=\"vision\",\n",
    "    )\n",
    "    return result.id\n",
    "\n",
    "# Getting the file ID\n",
    "file_id = create_file(\"arquivos/otter.png\")\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    input=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"input_text\", \"text\": \"what's in this image?\"},\n",
    "            {\n",
    "                \"type\": \"input_image\",\n",
    "                \"file_id\": file_id,\n",
    "            },\n",
    "        ],\n",
    "    }],\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
